{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Models, Prompts and Output Parsers\n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    " * Direct API calls to OpenAI\n",
    " * API calls through LangChain:\n",
    "   * Prompts\n",
    "   * Models\n",
    "   * Output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(r'C:\\Users\\DELL\\OneDrive\\Desktop\\chatbot\\env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_29064\\3294863152.py:13: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_29064\\3294863152.py:34: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  customer_response = chat(customer_messages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am frustrated that my blender lid flew off and splattered my kitchen walls with smoothie! To make matters worse, the warranty does not cover the cost of cleaning up my kitchen. I could really use your help right now, friend.\n",
      "{\n",
      "  \"gift\": true,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there\"]\n",
      "}\n",
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
      "price_value: Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
      "\n",
      "Format the output as JSON with the following keys:\n",
      "gift\n",
      "delivery_days\n",
      "price_value\n",
      "\n",
      "text: This leaf blower is pretty amazing. It has four settings: candle blower, gentle breeze, windy city, and tornado. \n",
      "It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. \n",
      "So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. \n",
      "It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n",
      "{\n",
      "  \"gift\": true,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
      "}\n",
      "{'gift': True, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]}\n",
      "<class 'dict'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "## Chat API : LangChain\n",
    "\n",
    "## Let's try how we can do the same using LangChain.\n",
    "\n",
    "### Import Libraries\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# Initialize the ChatOpenAI model with a specific temperature and model version\n",
    "chat = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "### Define Prompt Template\n",
    "# This template is designed to translate text into a specified style.\n",
    "template_string = \"Translate the text into a style that is {style}. text: {text}\"\n",
    "\n",
    "# Create the ChatPromptTemplate from the template string\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "# Define the style and example email message for translation\n",
    "customer_style = \"\"\"American English in a calm and respectful tone\"\"\"\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls \n",
    "with smoothie! And to make matters worse, the warranty don't cover the cost of \n",
    "cleaning up me kitchen. I need yer help right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "# Format the prompt to pass to the chat model\n",
    "customer_messages = prompt_template.format_messages(style=customer_style, text=customer_email)\n",
    "\n",
    "# Call the model with the formatted messages\n",
    "customer_response = chat(customer_messages)\n",
    "print(customer_response.content)\n",
    "\n",
    "### Output Parsers\n",
    "\n",
    "# Define example data for the output parsing section\n",
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing. It has four settings: candle blower, gentle breeze, windy city, and tornado. \n",
    "It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. \n",
    "So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. \n",
    "It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "# Define a new prompt template to extract information from the customer review\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
    "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
    "price_value: Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\"\n",
    "\n",
    "# Create a new ChatPromptTemplate using the review extraction template\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "\n",
    "# Format the review template with the example review text\n",
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "\n",
    "# Call the model to parse the review information\n",
    "response = chat(messages)\n",
    "print(response.content)  # Print the raw response from the model\n",
    "\n",
    "# Parse the LLM output into a Python dictionary\n",
    "# Define individual schemas for each piece of information we want to extract\n",
    "gift_schema = ResponseSchema(\n",
    "    name=\"gift\",\n",
    "    description=\"Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\"\n",
    ")\n",
    "delivery_days_schema = ResponseSchema(\n",
    "    name=\"delivery_days\",\n",
    "    description=\"How many days did it take for the product to arrive? If this information is not found, output -1.\"\n",
    ")\n",
    "price_value_schema = ResponseSchema(\n",
    "    name=\"price_value\",\n",
    "    description=\"Extract any sentences about the value or price, and output them as a comma separated Python list.\"\n",
    ")\n",
    "\n",
    "# Combine the schemas into a list to use with the output parser\n",
    "response_schemas = [gift_schema, delivery_days_schema, price_value_schema]\n",
    "\n",
    "# Create a StructuredOutputParser based on the defined response schemas\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# Get specific format instructions for the parser\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(messages[0].content)  # Print the formatted message content\n",
    "\n",
    "# Re-call the chat model with the formatted messages and instructions\n",
    "response = chat(messages)\n",
    "print(response.content)\n",
    "\n",
    "# Use JsonOutputParser to parse the response into a dictionary format\n",
    "message = AIMessage(content=response.content)\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "# Invoke the parser to extract data from the response content\n",
    "output_dict = output_parser.invoke(message)\n",
    "\n",
    "# Display the parsed dictionary and check the type\n",
    "print(output_dict)\n",
    "print(type(output_dict))\n",
    "\n",
    "# Access specific extracted data\n",
    "print(output_dict.get('delivery_days'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response content:\n",
      " {\n",
      "  \"gift\": true,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\n",
      "    \"It's slightly more expensive than the other leaf blowers out there\"\n",
      "  ]\n",
      "}\n",
      "Parsed output dictionary: {'gift': True, 'delivery_days': 2, 'price_value': [\"It's slightly more expensive than the other leaf blowers out there\"]}\n",
      "<class 'dict'>\n",
      "Delivery days: 2\n",
      "Gift: True\n",
      "Price value: [\"It's slightly more expensive than the other leaf blowers out there\"]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries from LangChain and other dependencies\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.messages import AIMessage\n",
    "import json\n",
    "\n",
    "# Initialize the ChatOpenAI model with temperature and model settings\n",
    "# This model will be used to process and respond to prompts\n",
    "chat = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Define a sample customer review text for extracting structured information\n",
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing. It has four settings: candle blower, gentle breeze, windy city, and tornado. \n",
    "It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. \n",
    "So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. \n",
    "It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "# Define a prompt template that instructs the model to extract specific information\n",
    "# The model should return details about the product as JSON\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
    "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
    "price_value: Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\"\n",
    "\n",
    "# Create a ChatPromptTemplate using the review extraction template\n",
    "# This template helps structure the input message for the model\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "\n",
    "# Format the review template with the example review text\n",
    "# This prepares a message containing the customer review text\n",
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "\n",
    "# Call the model to process the formatted message and extract the information\n",
    "response = chat(messages)\n",
    "print(\"Raw response content:\\n\", response.content)  # Print the raw response to inspect the format\n",
    "\n",
    "# Parse the response content into a dictionary using JsonOutputParser\n",
    "# JsonOutputParser converts JSON-formatted string responses into Python dictionaries\n",
    "message = AIMessage(content=response.content)\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "# Invoke the output parser to process the response content\n",
    "# This converts the response into a Python dictionary (output_dict)\n",
    "output_dict = output_parser.invoke(message)\n",
    "\n",
    "# Display the parsed dictionary to verify the extracted information\n",
    "print(\"Parsed output dictionary:\", output_dict)\n",
    "print(type(output_dict))  # Confirming the type of parsed output is a dictionary\n",
    "\n",
    "# Access and print specific extracted data from the parsed dictionary\n",
    "print(\"Delivery days:\", output_dict.get('delivery_days'))  # Number of days for delivery\n",
    "print(\"Gift:\", output_dict.get('gift'))  # Boolean indicating if it was a gift\n",
    "print(\"Price value:\", output_dict.get('price_value'))  # Price-related comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
