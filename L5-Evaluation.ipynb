{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(r'C:\\Users\\DELL\\OneDrive\\Desktop\\chatbot\\env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\venv\\Lib\\site-packages\\langchain\\chains\\llm.py:369: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping malformed example: {'qa_pairs': {'query': \"What materials are the Women's Campside Oxfords made of, and what features contribute to their comfort?\", 'answer': \"The Women's Campside Oxfords are made of soft canvas material for a broken-in feel and look. They also feature a comfortable EVA innersole with Cleansport NXT® antimicrobial odor control, a moderate arch contour, EVA foam midsole for cushioning and support, and a chain-tread-inspired molded rubber outsole with a modified chain-tread pattern.\"}}\n",
      "Skipping malformed example: {'qa_pairs': {'query': 'What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat?', 'answer': 'The small size has dimensions of 18\" x 28\" and the medium size has dimensions of 22.5\" x 34.5\".'}}\n",
      "Skipping malformed example: {'qa_pairs': {'query': \"What are some key features of the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece as described in the document?\", 'answer': 'Some key features of the swimsuit include bright colors, ruffles, exclusive whimsical prints, four-way-stretch and chlorine-resistant fabric, UPF 50+ rated fabric for sun protection, crossover no-slip straps, fully lined bottom for secure fit and maximum coverage, and the recommendation to machine wash and line dry for best results.'}}\n",
      "Skipping malformed example: {'qa_pairs': {'query': 'What is the fabric composition of the Refresh Swimwear V-Neck Tankini Contrasts top?', 'answer': 'The body of the swimtop is made from 82% recycled nylon and 18% Lycra® spandex, while the lining is made from 90% recycled nylon and 10% Lycra® spandex.'}}\n",
      "Skipping malformed example: {'qa_pairs': {'query': 'What technology sets the EcoFlex 3L Storm Pants apart from other waterproof pants?', 'answer': 'The EcoFlex 3L Storm Pants feature TEK O2 technology, which offers the most breathability tested and ensures that the wearer stays dry and comfortable during various outdoor activities and weather conditions.'}}\n",
      "Testing Query: Do the Cozy Comfort Pullover Set have side pockets?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: The Cozy Comfort Pullover Set does not mention having side pockets in the provided description.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Example 1:\n",
      "Question: Do the Cozy Comfort Pullover Set have side pockets?\n",
      "Expected Answer: Yes\n",
      "Predicted Answer: Yes, the Cozy Comfort Pullover Set does have side pockets.\n",
      "Predicted Grade: No grade available\n",
      "\n",
      "Example 2:\n",
      "Question: What collection is the Ultra-Lofty 850 Stretch Down Hooded Jacket from?\n",
      "Expected Answer: The DownTek collection\n",
      "Predicted Answer: The Ultra-Lofty 850 Stretch Down Hooded Jacket is from the DownTek collection.\n",
      "Predicted Grade: No grade available\n",
      "\n",
      "Access LangChain Plus Evaluation Platform:\n",
      "URL: https://www.langchain.plus/\n",
      "Invite Code: lang_learners_2023\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.evaluation.qa import QAGenerateChain, QAEvalChain\n",
    "import langchain\n",
    "\n",
    "# Step 1: Load CSV Data\n",
    "# Define the path to the CSV file and load the data using CSVLoader\n",
    "file_path = 'OutdoorClothingCatalog_1000.csv'  # Specify the file path of your CSV\n",
    "loader = CSVLoader(file_path=file_path)  # Load the CSV data using the CSVLoader\n",
    "data = loader.load()  # Load the data into a variable `data`\n",
    "\n",
    "# Step 2: Set Up the Embedding Model\n",
    "# Create the embedding model using OpenAI's embeddings\n",
    "embeddings = OpenAIEmbeddings()  # Using OpenAI's pre-trained embeddings for vectorizing text\n",
    "\n",
    "# Step 3: Create Index for Retrieval\n",
    "# Use the VectorstoreIndexCreator to create an index from the loaded data\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,  # Use in-memory search for indexing\n",
    "    embedding=embeddings  # Set the embedding model for vectorizing the data\n",
    ").from_loaders([loader])  # Load the index using the data from the CSV\n",
    "\n",
    "# Step 4: Initialize Chat Model (LLM)\n",
    "# Create the ChatOpenAI model with a specific temperature (0.0 for deterministic answers)\n",
    "llm = ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo')  # Using GPT-3.5-turbo for language generation\n",
    "\n",
    "# Step 5: Create Retrieval QA Chain\n",
    "# Set up the RetrievalQA chain using the ChatOpenAI model and the created index\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,  # Language model (LLM) for question answering\n",
    "    chain_type=\"stuff\",  # Type of chain for handling the document retrieval and answering\n",
    "    retriever=index.vectorstore.as_retriever(),  # Use the vectorstore's retriever for fetching relevant documents\n",
    "    verbose=True,  # Enable verbose output to see additional debug information\n",
    "    chain_type_kwargs={\"document_separator\": \"<<<<>>>>>\"}\n",
    ")\n",
    "\n",
    "# Step 6: Example Queries for Testing\n",
    "# Define a list of example queries and expected answers for testing\n",
    "examples = [\n",
    "    {\"query\": \"Do the Cozy Comfort Pullover Set have side pockets?\", \"answer\": \"Yes\"},\n",
    "    {\"query\": \"What collection is the Ultra-Lofty 850 Stretch Down Hooded Jacket from?\", \"answer\": \"The DownTek collection\"}\n",
    "]\n",
    "\n",
    "# Step 7: Generate Additional Examples Using LLM\n",
    "# Generate new question-answer examples from the first few rows of the data\n",
    "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI(model='gpt-3.5-turbo'))  # Create a chain to generate QA pairs\n",
    "new_examples = example_gen_chain.apply_and_parse([{\"doc\": t} for t in data[:5]])  # Apply the chain to the first 5 rows of data\n",
    "\n",
    "# Ensure new examples have the correct structure\n",
    "# We will now iterate over the newly generated examples to check for the 'query' key.\n",
    "for ex in new_examples:\n",
    "    if 'query' not in ex:\n",
    "        print(f\"Skipping malformed example: {ex}\")\n",
    "    else:\n",
    "        examples.append(ex)  # Only add valid examples that contain 'query'\n",
    "\n",
    "# Step 8: Testing a Query\n",
    "# Test one of the queries from the examples list\n",
    "print(\"Testing Query:\", examples[0][\"query\"])  # Print the query being tested\n",
    "print(\"Response:\", qa_chain.run(examples[0][\"query\"]))  # Get and print the response to the query\n",
    "\n",
    "# Step 9: LLM-Assisted Evaluation (Optional)\n",
    "# Ensure the examples are formatted correctly before applying the QA chain\n",
    "formatted_examples = [{\"query\": example[\"query\"]} for example in examples if 'query' in example]  # Filter out examples without 'query'\n",
    "\n",
    "# Now we apply the `qa_chain` to the formatted examples\n",
    "# The `apply()` method requires input in the form of a list of dictionaries containing at least the 'query' key\n",
    "predictions = qa_chain.apply(formatted_examples)  # Apply the QA chain to the formatted examples\n",
    "\n",
    "# Step 10: Initialize Evaluation Chain\n",
    "# Create the QAEvalChain to evaluate the predictions generated by the QA chain\n",
    "eval_chain = QAEvalChain.from_llm(ChatOpenAI(temperature=0, model='gpt-3.5-turbo'))\n",
    "\n",
    "# Step 11: Evaluate Predictions and Compare to Expected Answers\n",
    "# Compare the predicted answers to the expected answers and grade them\n",
    "graded_outputs = eval_chain.evaluate(examples, predictions)\n",
    "\n",
    "# Step 12: Display Evaluation Results\n",
    "# Loop through each example to display the results of the evaluation\n",
    "for i, example in enumerate(examples):\n",
    "    print(f\"\\nExample {i + 1}:\")\n",
    "    print(f\"Question: {predictions[i]['query']}\")  # Print the predicted question\n",
    "    print(f\"Expected Answer: {example['answer']}\")  # Print the expected answer\n",
    "    print(f\"Predicted Answer: {predictions[i]['result']}\")  # Print the predicted answer from the model\n",
    "    grade = graded_outputs[i].get('text', graded_outputs[i].get('evaluation', 'No grade available'))  # Get the grade for the prediction\n",
    "    print(f\"Predicted Grade: {grade}\")  # Print the grade for the predicted answer\n",
    "\n",
    "# Step 13: Access LangChain Plus (Optional)\n",
    "# Print LangChain Plus details for evaluation and further improvements\n",
    "print(\"\\nAccess LangChain Plus Evaluation Platform:\")\n",
    "print(\"URL: https://www.langchain.plus/\")  # LangChain Plus platform URL\n",
    "print(\"Invite Code: lang_learners_2023\")  # Example invite code for LangChain Plus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
